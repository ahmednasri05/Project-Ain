{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f772723f",
   "metadata": {},
   "source": [
    "# Perceptual hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3bfd2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imagehash\n",
    "from PIL import Image\n",
    "\n",
    "def generate_video_fingerprint(video_path, interval_seconds=2):\n",
    "    \"\"\"\n",
    "    Samples a video every X seconds and returns a list of 64-bit binary pHashes.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {video_path}\")\n",
    "        return []\n",
    "\n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = total_frames / fps\n",
    "    \n",
    "    hashes = []\n",
    "    \n",
    "    # Calculate frame step (e.g., at 30fps, every 2s is 60 frames)\n",
    "    frame_step = int(fps * interval_seconds)\n",
    "\n",
    "    current_frame = 0\n",
    "    while current_frame < total_frames:\n",
    "        # Set the video position to the specific frame\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, current_frame)\n",
    "        success, frame = cap.read()\n",
    "        \n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        # 1. Convert OpenCv BGR to PIL RGB\n",
    "        color_coverted = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        pil_img = Image.fromarray(color_coverted)\n",
    "\n",
    "        # 2. Compute pHash\n",
    "        # phash returns a 64-bit hash (8x8 grid)\n",
    "        hash_obj = imagehash.phash(pil_img)\n",
    "        \n",
    "        # 3. Convert Hex to 64-bit Binary String for Supabase BIT(64)\n",
    "        # We use zfill(64) to ensure leading zeros aren't lost\n",
    "        hash_as_int = int(str(hash_obj), 16)\n",
    "        binary_hash = bin(hash_as_int)[2:].zfill(64)\n",
    "\n",
    "        hashes.append({\n",
    "            \"timestamp_seconds\": round(current_frame / fps, 2),\n",
    "            \"hash\": binary_hash\n",
    "        })\n",
    "\n",
    "        # Advance to the next 2-second mark\n",
    "        current_frame += frame_step\n",
    "    cap.release()\n",
    "    return hashes\n",
    "\n",
    "def are_identical(first_path, second_path):\n",
    "    hashes1 = generate_video_fingerprint(first_path, 2)\n",
    "    hashes2 = generate_video_fingerprint(second_path,4)\n",
    "    # INSERT_YOUR_CODE\n",
    "    def hamming_distance(hash1, hash2):\n",
    "        \"\"\"Compute the Hamming distance between two 64-bit binary strings.\"\"\"\n",
    "        # Assumes input are 64-char strings of '0' and '1'\n",
    "        return sum(c1 != c2 for c1, c2 in zip(hash1, hash2))\n",
    "\n",
    "    # For each timestamped hash in hashes1, find the minimum Hamming distance to hashes2\n",
    "    # If >70% of hashes have corresponding matches within a small threshold (e.g., <=6 bits), declare identical.\n",
    "    threshold = 6\n",
    "    matches = 0\n",
    "    for h1 in hashes1:\n",
    "        h1_hash = h1[\"hash\"]\n",
    "        # Find min hamming dist for this h1 to any in hashes2\n",
    "        min_dist = min(hamming_distance(h1_hash, h2[\"hash\"]) for h2 in hashes2)\n",
    "        if min_dist <= threshold:\n",
    "            matches += 1\n",
    "\n",
    "    match_fraction = matches / max(len(hashes1), 1)\n",
    "    # You can adjust fraction (e.g., 0.7 == \"70% of hashes match closely\")\n",
    "    return matches \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2ddcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.0s | Hash: 1100011101111000001110001100011101011011001110000000011111000011\n",
      "Time: 2.0s | Hash: 1001111001010000001000011011110101011110100000000011000111111111\n",
      "Time: 4.0s | Hash: 1001111001101000011000111001100110001100011001101101001010011101\n",
      "Time: 6.0s | Hash: 1000100101110110001101001100100100100110001101001101110111001011\n",
      "Time: 8.0s | Hash: 1011011101101100010000001010101110101101110101100101001000110001\n",
      "Time: 10.0s | Hash: 1101001100111110011000011000010110011110011000110011111011000000\n",
      "Time: 12.0s | Hash: 1100001100110100001111001101100011100110001001010001100111111010\n",
      "Time: 14.0s | Hash: 1101110000100011000000111111110001001100000000010111111111101100\n",
      "Time: 16.0s | Hash: 1101110100101001000000001110011011111111100111010000000001100111\n",
      "Time: 18.0s | Hash: 1100010000111111001110111101000001000100110011110011101101100000\n",
      "Time: 20.0s | Hash: 1100001100110100001111011100101111000010001101100001100111001011\n"
     ]
    }
   ],
   "source": [
    "# --- Example Usage ---\n",
    "video_file = \"C:/Users/shels/Documents/wezareit el dakhleya/dakhleyaVideos/blue car swerving/blue car swerving.mp4\"\n",
    "fingerprints = generate_video_fingerprint(video_file)\n",
    "for entry in fingerprints:\n",
    "   print(f\"Time: {entry['timestamp_seconds']}s | Hash: {entry['hash']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfb5bc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(are_identical(video_file,video_file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
